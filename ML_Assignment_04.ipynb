{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME3fkvXqkH57vqQ+vd/GXr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirtiKousik/Machine_Learngin_Assignments_ineuron/blob/main/ML_Assignment_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
      ],
      "metadata": {
        "id": "bqin4D25TbA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Preparing to work with machine learning modeling typically involves several key tasks, including:\n",
        "\n",
        "    1. Data collection: Gathering the data needed to train the machine learning model, including determining what data is relevant and available.\n",
        "\n",
        "    2. Data cleaning and preprocessing: This involves cleaning up the data and converting it into a format suitable for machine learning algorithms, including dealing with missing values, outliers, and inconsistencies.\n",
        "\n",
        "    3. Data exploration and visualization: Exploring the data and identifying patterns, correlations, and relationships using visualizations.\n",
        "\n",
        "    4. Feature engineering: Selecting or creating the features, or input variables, that will be used to train the machine learning model.\n",
        "\n",
        "    5. Model selection: Choosing an appropriate machine learning algorithm or model for the task at hand, considering factors such as the type of problem, the size of the dataset, and the available computing resources.\n",
        "\n",
        "    6. Training the model: Using the selected algorithm to train the model on the data.\n",
        "\n",
        "    7. Model evaluation: Assessing the performance of the model, often using metrics such as accuracy, precision, and recall.\n",
        "\n",
        "    8. Model tuning: Adjusting the parameters of the model to improve its performance.\n",
        "\n",
        "    9. Deployment: Integrating the model into an application or system for practical use.\n",
        "\n",
        "- These tasks may be iterative, with each step informing the others, and may require significant expertise and domain knowledge in order to be carried out effectively."
      ],
      "metadata": {
        "id": "NF4tUvfCTsFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
      ],
      "metadata": {
        "id": "PFHPTswJTm-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In machine learning, data is typically categorized into three types:\n",
        "\n",
        "    1. Numerical data: This type of data consists of numerical values, which can be either continuous or discrete. Examples include age, weight, height, temperature, etc.\n",
        "\n",
        "    2. Categorical data: This type of data consists of non-numerical values, which are typically represented by strings or labels. Examples include gender, marital status, product types, etc.\n",
        "\n",
        "    3. Text data: This type of data consists of unstructured text, such as news articles, emails, reviews, tweets, etc.\n",
        "\n",
        "- Here are some examples of each type of data:\n",
        "\n",
        "    1. Numerical data: A dataset containing information about houses, including their prices, square footage, number of bedrooms and bathrooms, and location.\n",
        "\n",
        "    2. Categorical data: A dataset containing information about customer demographics, including age, gender, income level, and education level.\n",
        "\n",
        "    3. Text data: A dataset of movie reviews, which includes the text of the review and a binary label indicating whether the review is positive or negative."
      ],
      "metadata": {
        "id": "KmOZxzj2T5W_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Distinguish:\n",
        "\n",
        "1. Numeric vs. categorical attributes\n",
        "\n",
        "2. Feature selection vs. dimensionality reduction"
      ],
      "metadata": {
        "id": "8NYcnAlyUC4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Numeric vs. categorical attributes:\n",
        "Numeric attributes are quantitative variables that represent measurements or counts on a numerical scale, such as height, weight, or temperature. They can be continuous or discrete and are often represented as real numbers. In contrast, categorical attributes are qualitative variables that represent non-numeric attributes such as color, gender, or occupation. They have a limited number of possible values, and the values have no inherent order or numerical meaning.\n",
        "\n",
        "2. Feature selection vs. dimensionality reduction:\n",
        "Feature selection and dimensionality reduction are two techniques used to reduce the number of features in a dataset, but they differ in their approach. Feature selection involves selecting a subset of the original features that are most relevant to the problem at hand. This can be done using various techniques such as correlation analysis, information gain, or forward/backward selection. The goal is to reduce the dimensionality of the data while retaining as much useful information as possible.\n",
        "\n",
        "- On the other hand, dimensionality reduction aims to transform the original high-dimensional data into a lower-dimensional representation, while preserving as much of the variance in the data as possible. This is typically done using techniques such as principal component analysis (PCA) or t-distributed stochastic neighbor embedding (t-SNE). The goal is to simplify the data while retaining the most relevant information, making it easier to visualize and analyze."
      ],
      "metadata": {
        "id": "QGiSHTClUVot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Make quick notes on any two of the following:\n",
        "\n",
        "1. The histogram\n",
        "\n",
        "2. Use a scatter plot\n",
        "\n",
        "3. PCA (Personal Computer Aid)"
      ],
      "metadata": {
        "id": "ZvlLSbmbUOh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The histogram:\n",
        "    - A histogram is a graphical representation of the distribution of data. It represents data by forming continuous bars where the height of each bar corresponds to the frequency or count of data values falling within a specific interval. A histogram is used to show the underlying frequency distribution of a set of continuous or discrete data. It is useful in identifying patterns, outliers, and skewness in the data.\n",
        "\n",
        "- Scatter plot:\n",
        "    - A scatter plot is a graph that uses dots to represent data points in two dimensions. The position of each dot on the horizontal and vertical axis represents the values of two variables. Scatter plots are used to observe and show the relationship between two variables. A scatter plot can be used to identify the existence of a pattern or correlation between two variables, and to identify any outliers or anomalies in the data. It is also useful in identifying clusters or groups of data points in high-dimensional datasets.\n",
        "\n",
        "- PCA (Principal Component Analysis):\n",
        "    - PCA is a statistical technique that is used to reduce the number of dimensions in a dataset while retaining the maximum amount of variation in the data. It works by identifying the principal components of the data, which are linear combinations of the original variables that explain the maximum amount of variance in the data. PCA is used to reduce the dimensionality of the data, which can help simplify the data and make it easier to analyze. It is commonly used in image processing, speech recognition, and natural language processing."
      ],
      "metadata": {
        "id": "kIp0RmX8UnLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
      ],
      "metadata": {
        "id": "ENlviVOVUcT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Investigating data is necessary to gain insights and make informed decisions based on evidence. It helps to identify patterns, relationships, and trends in the data, and to detect anomalies and outliers that may require further investigation.\n",
        "\n",
        "- There can be differences in how qualitative and quantitative data are explored due to their unique characteristics. Qualitative data is typically subjective and exploratory in nature, and may involve analyzing textual or visual data to identify themes and patterns. In contrast, quantitative data is typically numerical and involves statistical analysis to identify patterns and relationships. However, both types of data require careful exploration and analysis to gain meaningful insights."
      ],
      "metadata": {
        "id": "32-D_eO7WGHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. What are the various histogram shapes? What exactly are â€˜bins&#39;?\n",
        "\n"
      ],
      "metadata": {
        "id": "zlY7jljbUetG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Histograms can have different shapes, including:\n",
        "\n",
        "    1. Bell-shaped: also known as normal distribution, where the data is centered around a single peak with decreasing frequency on both sides of the peak.\n",
        "\n",
        "    2. Skewed right: also known as positively skewed, where the data has a tail to the right and most of the values are concentrated on the left side of the histogram.\n",
        "\n",
        "    3. Skewed left: also known as negatively skewed, where the data has a tail to the left and most of the values are concentrated on the right side of the histogram.\n",
        "\n",
        "    4. Bimodal: where the data has two distinct peaks.\n",
        "\n",
        "- Bins are the intervals into which the range of values in the data are divided in a histogram. Bins are used to group the data into discrete segments and create a visual representation of the frequency distribution of the data. The number of bins in a histogram affects the shape of the distribution and can impact the insights gained from the analysis. The choice of bin size or width should take into consideration the range and distribution of the data and the purpose of the analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pgzg77wXWS5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. How do we deal with data outliers?\n",
        "\n"
      ],
      "metadata": {
        "id": "S09MUCSuUglj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Outliers are extreme values that lie far away from the majority of the data points. Dealing with outliers depends on the context of the data and the analysis being performed. Here are some common approaches for handling outliers:\n",
        "\n",
        "    - Remove the outliers: In some cases, outliers can be identified and removed from the dataset if they are considered to be errors or anomalies that may bias the analysis.\n",
        "\n",
        "    - Transform the data: Data transformation techniques such as log transformation or Box-Cox transformation can help to reduce the impact of outliers on the analysis.\n",
        "\n",
        "    - Winsorization: Winsorization is a method that replaces extreme values with less extreme values to reduce the influence of outliers on the analysis. The values beyond a certain threshold are replaced with the maximum or minimum value in the dataset.\n",
        "\n",
        "    - Keep the outliers: In some cases, outliers may contain valuable information or insights, and removing them may lead to biased results. In these cases, it may be better to keep the outliers and report them separately.\n",
        "\n",
        "- The approach chosen for dealing with outliers should be carefully considered and documented, and the impact of the approach on the analysis should be assessed. It is also important to investigate the cause of outliers to determine if they are errors or genuine data points that require further investigation."
      ],
      "metadata": {
        "id": "ZeR-qxHqWjfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
      ],
      "metadata": {
        "id": "yIGQkUibUh_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Central tendency measures are statistical indicators that describe the typical value or central location of a dataset. The most common central tendency measures are:\n",
        "\n",
        "    1. Mean: the arithmetic average of a set of numbers, calculated by summing all the values and dividing by the total number of values.\n",
        "\n",
        "    2. Median: the middle value in a dataset when the values are arranged in order of magnitude.\n",
        "\n",
        "    3. Mode: the most frequently occurring value in a dataset.\n",
        "\n",
        "- The mean and median are the two most commonly used central tendency measures, but they can differ depending on the distribution of the data.\n",
        "\n",
        "- In some datasets, the mean can vary significantly from the median, especially in skewed distributions with outliers. This happens because the mean is affected by extreme values, while the median is less sensitive to them. When extreme values are present, they can pull the mean towards their side of the distribution, while the median remains unaffected.\n",
        "\n",
        "- For example, in a dataset with values 1, 2, 3, 4, and 100, the mean is 22 (sum of values divided by 5), while the median is 3. In this case, the extreme value 100 has a large influence on the mean, while the median is closer to the majority of the values.\n",
        "\n",
        "- It's important to choose the appropriate central tendency measure based on the nature and distribution of the data and to consider other measures of variability and dispersion in conjunction with central tendency measures to get a comprehensive understanding of the dataset."
      ],
      "metadata": {
        "id": "tq68Pn6uWtD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?\n",
        "\n"
      ],
      "metadata": {
        "id": "dKGVL5LkWcWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A scatter plot is a graphical representation of bivariate data that shows the relationship between two variables. Each data point is plotted as a point on the graph with one variable on the x-axis and the other variable on the y-axis. The pattern of the points on the graph can provide insights into the strength, direction, and shape of the relationship between the two variables.\n",
        "\n",
        "- A scatter plot can be used to investigate bivariate relationships by examining the following features:\n",
        "\n",
        "    1. Direction: The direction of the relationship can be positive, negative, or no relationship.\n",
        "\n",
        "    2. Strength: The strength of the relationship can be strong, moderate, or weak.\n",
        "\n",
        "    3. Form: The form of the relationship can be linear, nonlinear, or clusters.\n",
        "\n",
        "    4. Outliers: Outliers can be identified as data points that are far away from the general pattern of the other data points on the scatter plot.\n",
        "\n",
        "    5. Correlation: Correlation coefficient can be calculated to quantify the degree of association between the two variables.\n",
        "\n",
        "- A scatter plot can help to identify outliers as data points that fall far away from the general pattern of the other data points on the scatter plot. Outliers can indicate errors in the data, anomalies, or unusual observations that require further investigation. The location of the outliers on the scatter plot can provide insights into their nature and possible causes. Outliers can be removed if they are considered to be errors or if they significantly affect the analysis. However, in some cases, outliers may contain valuable information or insights and should be retained and analyzed separately."
      ],
      "metadata": {
        "id": "FsghlHKHW4uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Describe how cross-tabs can be used to figure out how two variables are related."
      ],
      "metadata": {
        "id": "Oz1SRY56Weir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Cross-tabulation, also known as a contingency table or a cross-tab, is a table that displays the frequency distribution of two categorical variables. It can be used to examine the relationship between two variables and determine if they are associated with each other.\n",
        "\n",
        "- The cross-tab shows the distribution of one variable broken down by the categories of the other variable. For example, if we are examining the relationship between gender and preference for a particular product, we can construct a cross-tab with gender as one variable and preference as the other variable. The table would display the number or proportion of males and females who prefer the product and those who do not.\n",
        "\n",
        "- Cross-tabs allow us to examine the relationship between two variables by calculating conditional frequencies and percentages. We can examine the differences in the frequency or proportion of one variable within each category of the other variable. This allows us to identify patterns and trends that may exist in the data.\n",
        "\n",
        "- We can also use cross-tabs to calculate measures of association such as chi-square, phi coefficient, and Cramer's V. These measures allow us to determine the strength and direction of the association between the two variables.\n",
        "\n",
        "- In summary, cross-tabs can be used to:\n",
        "\n",
        "    - Display the frequency distribution of two categorical variables.\n",
        "    - Examine the relationship between two variables.\n",
        "    - Calculate conditional frequencies and percentages.\n",
        "    - Identify patterns and trends in the data.\n",
        "    - Calculate measures of association to determine the strength and direction of the association between the two variables."
      ],
      "metadata": {
        "id": "aLk8vJDaXDLq"
      }
    }
  ]
}